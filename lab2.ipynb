{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab2 - Concrete compressive strength regression\n",
    "Author: *BHAVYAI GUPTA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Function definitions\n",
    "\n",
    "To find the best model, we follow the published article where root-mean squared error (rms) was used as a score function. The rms score function needs to be minimized, because the optimal score is 0, larger values are worse performances. \n",
    "\n",
    "In scikit-learn, only *maximization* is implemented. Hence, it is customary to maximize the *negative* rms. scitkit-learn provides a scoring function `neg_root_mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "def get_regressor_neg_rms(model, X, y, cv=7):\n",
    "    '''Calculate train and validation score for regressor (model) using cross-validation\n",
    "        \n",
    "        score is negative root mean-squared error (rms).\n",
    "        \n",
    "        model (sklearn classifier): Regressor to train and evaluate\n",
    "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
    "        y (numpy.array or pandas.Series): Target vector\n",
    "        \n",
    "        returns: mean training negative rms, mean validation negative rms\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #TODO: add function body here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "yellowbrick concrete  \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Print the README of the concrete Dataset object. Load the Dataset object by using `return_dataset=True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Concrete Compressive Strength\n",
      "\n",
      "**Downloaded from the UCI Machine Learning Repository on October 13, 2016.**\n",
      "\n",
      "- Multivariate Data Set\n",
      "- Real Attributes\n",
      "- 1,030 Instances\n",
      "- 9 attributes\n",
      "- Well suited for _regression_ tasks\n",
      "- [https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength)\n",
      "\n",
      "## Abstract\n",
      "\n",
      "Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients.\n",
      "\n",
      "## Description\n",
      "\n",
      "Given are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database.\n",
      "\n",
      "## Attributes\n",
      "\n",
      "- cement (kg)\n",
      "- blast furnace slag (kg)\n",
      "- fly ash (kg)\n",
      "- water (kg)\n",
      "- superplasticizer (kg)\n",
      "- coarse aggregate (kg)\n",
      "- fine aggregate (kg)\n",
      "- age (day)\n",
      "- compressive strength (MPa)\n",
      "\n",
      "## Citation\n",
      "\n",
      "Yeh, I-C. \"Modeling of strength of high-performance concrete using artificial neural networks.\" Cement and Concrete research 28.12 (1998): 1797-1808.\n"
     ]
    }
   ],
   "source": [
    "from yellowbrick.datasets.loaders import load_concrete\n",
    "\n",
    "# loading concrete dataset as a whole\n",
    "concrete_data = load_concrete(return_dataset=True)\n",
    "\n",
    "# printing the contents to README\n",
    "print(concrete_data.README)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 1:* What is the target variable name and units in this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the information at [here](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength) and in the README, the target variable is `Concrete compressive strength` and its unit is **MPa**. The variable is stored as column **strength**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare the feature matrix and target vector\n",
    "Load the concrete data set into feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print dimensions and type of `X`, `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X       = <class 'pandas.core.frame.DataFrame'>\n",
      "Dimension of X  = (1030, 8)\n",
      "\n",
      "Type of y       = <class 'pandas.core.series.Series'>\n",
      "Dimension of y  = (1030,)\n"
     ]
    }
   ],
   "source": [
    "# loading concrete dataset into feature matrix X and target vector y\n",
    "X, y = concrete_data.to_data()\n",
    "\n",
    "print(\"Type of X       = {}\\nDimension of X  = {}\\n\\nType of y       = {}\\nDimension of y  = {}\".format(type(X), X.shape, type(y), y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Range of each feature\n",
    "To get an idea if the features are on the same scale, we inspect the range of features.\n",
    "\n",
    "Print the minimum and maximum of each feature in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print range (minimum and maximum) of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Boxplot of features \n",
    "Using seaborn boxplot, plot all features. This provides a visual view of feature ranges.\n",
    "\n",
    "Add y-axis label indicating units, and a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add boxplot of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Correlation heatmap of features \n",
    "\n",
    "To understand if pairs of features are potentially related, contain similar information, pair-wise cross-correlation can be calculated. Models benefit most from un-correlated features.\n",
    "\n",
    "Using pandas `corr()` method, create the cross-correlations between all features. Plot this cross-correlation object using seaborn `heatmap()` with parameters `vmin=-1, vmax=1, annot=True, cmap='BrBG'`. Add a title.\n",
    "\n",
    "Pandas `corr()` calculates [Pearson correlation ](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) :\n",
    ">  It has a value between +1 and −1. A value of +1 is total positive linear correlation, 0 is no linear correlation, and −1 is total negative linear correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add pairwise cross-correlation heatmap of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Histogram of target variable \n",
    "\n",
    "To understand if all target values are equally represented in the data, we analyze how many samples of each target value we have available. The histogram of the target vector can visualize this distribution.\n",
    "\n",
    "Using seaborn `displot()`, plot the histogram of the target vector. Add a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add histogram of targect vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create training and test sets\n",
    "\n",
    "Using scikit-learn `train_test_split()` with parameters `random_state=37`, `test_size=0.2`, split `X` and `y` into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train-test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare models using cross-validation\n",
    "\n",
    "Create a list containing a `LinearRegression()`, `RandomForestRegressor(random_state=64)` and `GradientBoostingRegressor(random_state=79)` objects.\n",
    "\n",
    "Iterate this list, compute the negative root mean-squared error using the `get_regressor_neg_rms()` function, and print the training and validation scores with **2 decimal places**. Use 7-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Calling get_regressor_neg_rms() for each model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 2:* For each of the three models, state if models are potentially over- or underfitting and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find a better model\n",
    "\n",
    "Use the `RandomForestRegressor(random_state=64)` and find the best combination of `max_depth` from the list of `[10, 15, 20]`, and `n_estimators` from the list of `[50, 100, 150]`.\n",
    "\n",
    "Use nested for-loops to iterate these two lists, compute the negative root mean-squared error of the corresponding `RandomForestRegressor(random_state=64)` using the `get_regressor_neg_rms()` function, and print the training and validation scores with **2 decimal places**. Use 7-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Calling get_regressor_neg_rms() for each parameter pair\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 3:* Which combination of `max_depth` and `n_estimators` produced the best validation score? Report this score here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrain best model\n",
    "\n",
    "Create a `RandomForestRegressor(random_state=64)` with the best pair of `max_depth` and `n_estimators`, and retrain this model on all training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: retrain the best estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate best model on training and test data\n",
    "### 7.1 Root mean-squared error and R-squared\n",
    "\n",
    "For the retrained best estimator, print the root mean-squared error (**2 decimal places**) and R-squared (**3 decimal places**) for training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print rms and r-squared for training and test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4:* How does this test score compare to the polynomial regression and neural network reported in the article? Do we outperform the reported models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Predicted vs actual strength plot\n",
    "Using a scatterplot, show predicted strength on the x axis and actual strength on the y axis with data from the test set. With this plot, we can see where we make errors.\n",
    "\n",
    "Add a line of unity (diagonal with slope 1 and offset 0). Ideally, all points would be on this line. We look for points being distributed equally around the line of unity.\n",
    "\n",
    "Add x-axis, y-axis labels including units, and a title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: predicted-actual plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Residual plot\n",
    "Using a scatterplot, show predicted strength on the x axis and the *difference* between actual and predicted strength on the y axis with data from the test set. This is an alternative way to see where errors are made.\n",
    "\n",
    "We look for residuals being distributed equally around the zero horizontal line.\n",
    "\n",
    "Add x-axis, y-axis labels including units, and a title.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Residual plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In conclusion, comment on the following items:\n",
    "- Did we find a model that outperformes the polynomial regression reported in the reference article? Explain.\n",
    "- Did we find a model that outperformes the neural network reported in the reference article? Explain.\n",
    "- What was the assumption about the dataset and the reference article? How does this affect your conclusions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating while working on this assignment.\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Optional - use grid search to find the best model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_grid_search_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-1. Hyperparameter tuning using grid search \n",
    "\n",
    "The inital cross-validation above showed that both DecisionTree based models might have merit. Next, the hyperparameters are tuned using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-1.1 Grid search for RandomForestRegressor\n",
    "\n",
    "Perform grid search using `GridSearchCV` for the `RandomForestRegressor(random_state=64)`.\n",
    "\n",
    "Grid search to use 7-fold cross-validation, and `neg_root_mean_squared_error` as the scoring function.\n",
    "\n",
    "Use the following hyperparameters and values:\n",
    "- `'n_estimators': [100, 200, 500]`\n",
    "- `'max_depth': [ 11, 13, 15, 17]`\n",
    "- `'max_features': ['auto', 'log2', None]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Setup grid search for RandomForestRegressor(random_state=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: perform the grid search by calling fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the best score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-5.2 Grid search for gradient boosted tree\n",
    "\n",
    "Perform grid search using `GridSearchCV` for the `GradientBoostingRegressor(random_state=79)`.\n",
    "\n",
    "Grid search to use 7-fold cross-validation, and `neg_root_mean_squared_error` as the scoring function.\n",
    "\n",
    "Use the following hyperparameters and values:\n",
    "- `'n_estimators': [100, 200, 500]`\n",
    "- `'max_depth': [1, 3, 5, 7]`\n",
    "- `'learning_rate': [0.01, 0.1, 1.0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Setup grid search for GradientBoostingRegressor(random_state=79)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: perform the grid search by calling fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the best score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question A-1:* Which of the two models produces the best score? What is the best score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-2. Retrain best model\n",
    "\n",
    "Get the best estimator from the two grid searches above and retrain this model on all training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: retrain the best estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-3. Model evaluation and conclusion\n",
    "\n",
    "Repeat steps in Section 7 above for the best model.\n",
    "\n",
    "Revisit your conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fde45515710cbe4f4cf44a8ddef1b298277709bd6c5462499553af68a98f2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
